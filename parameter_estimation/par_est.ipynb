{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "## 1D Linear operator with one parameter\n",
    "\n",
    "\n",
    "This chapter introduces a basic example of the framework developed in Chapter 3. We take a one-dimensional system with a single parameter and extract an operator out of it.\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}_x^\\phi u(x) &= f(x) \\\\\n",
    "\\mathcal{L}_x^\\phi &:= \\phi \\cdot + \\frac{d}{dx}\\cdot\n",
    "\\end{align*}\n",
    "\n",
    "It is trivial to verify linearity of the operator:\n",
    "\n",
    "\\begin{align*}\n",
    "u, f : [0, 2\\pi] &\\rightarrow \\mathbb{K}, \\alpha, \\beta \\in \\mathbb{R} \\\\\n",
    "\\mathcal{L}_x^\\phi (\\alpha u + \\beta f) &= \\phi (\\alpha u + \\beta f) + \\frac{d}{dx}(\\alpha u + \\beta f) \\\\\n",
    "&= \\alpha \\phi u + \\beta \\phi f + \\alpha \\frac{d}{dx}u + \\beta \\frac{d}{dx}f \\\\\n",
    "&= \\alpha \\mathcal{L}_x^\\phi u + \\beta \\mathcal{L}_x^\\phi f\n",
    "\\end{align*}\n",
    "\n",
    "One of the solutions to this system might be:\n",
    "\n",
    "\\begin{align*}\n",
    "u(x) &= x^3 \\\\\n",
    "f(x) &= \\phi x^3 + 3x^2 \\\\\n",
    "x &\\in [0, 1]\n",
    "\\end{align*}\n",
    "\n",
    "We define Gaussian priors on the input and output:\n",
    "\n",
    "\\begin{align*}\n",
    "u(x) &\\sim \\mathcal{GP}(0, k_{uu}(x,x',\\theta)) \\\\\n",
    "f(x) &\\sim \\mathcal{GP}(0, k_{ff}(x,x',\\theta,\\phi))\n",
    "\\end{align*}\n",
    "\n",
    "A noisy data model for the above system can be defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "y_u &= u(X_u) + \\epsilon_u; \\epsilon_u \\sim \\mathcal{N}(0, \\sigma_u^2I)\\\\\n",
    "y_f &= f(X_f) + \\epsilon_f; \\epsilon_f \\sim \\mathcal{N}(0, \\sigma_f^2I)\n",
    "\\end{align*}\n",
    "\n",
    "For the sake of simplicity, we ignore the noise terms $\\epsilon_u$ and $\\epsilon_f$ while simulating the data. They're nevertheless beneficial, when computing the negative log marginal likelihood (NLML) so that the resulting covariance matrix is mostly more well-behaved for reasons as they were outlined in the **!!!preface(if it's in the paper!)**.\n",
    "\n",
    "\n",
    "For the parameter estimation problem for the linear operator described above, we are given $\\{X_u, y_u\\}$, $\\{X_f, y_f\\}$ and we need to estimate $\\phi$.\n",
    "\n",
    "\n",
    "**Remark** : A number of code cells from the notebook are missing in the report. This has been done to improve readability. For the complete notebook, please check the github repository.\n",
    "\n",
    "\n",
    "#### Step 1: Simulate data\n",
    "\n",
    "\n",
    "We use $\\phi = 2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simulated_data(n1, n2, phi):\n",
    "    x_u = np.random.rand(n1)\n",
    "    y_u = np.power(x_u, 3)\n",
    "    x_f = np.random.rand(n2)\n",
    "    y_f = phi*np.power(x_f, 3) + 3*np.power(x_f,2)\n",
    "    return(x_u, y_u, x_f, y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x1104fb048>, <matplotlib.text.Text at 0x1104e6940>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_u, y_u, x_f, y_f) = get_simulated_data(10, 7, 2)\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, sharey=True, figsize=(10,3))\n",
    "f.suptitle(\"Input and Output for the operator\")\n",
    "ax1.plot(x_u, y_u, 'o')\n",
    "ax1.set(xlabel= \"x\", ylabel= \"u(x)\")\n",
    "ax2.plot(x_f, y_f, 'ro')\n",
    "ax2.set(xlabel= \"x\", ylabel= \"f(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAADmCAYAAAB79plGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLPTMgkSZJ69v8B40I0eMOohG0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11044f0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Evaluate kernels\n",
    "\n",
    "\n",
    "We use the RBF kernel defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "k_{uu}(x_i, x_j; \\theta) = \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2)\n",
    "\\end{align*}\n",
    "\n",
    "throughout the report. It is worth noting that this step uses information about $\\mathcal{L}_x^\\phi$ but not about $u(x)$ or $f(x)$. The derivatives are computed using *sympy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_i, x_j, theta, l, phi = sp.symbols('x_i x_j theta l phi')\n",
    "kuu_sym = theta*sp.exp(-l*((x_i - x_j)**2))\n",
    "kuu_fn = sp.lambdify((x_i, x_j, theta, l), kuu_sym, \"numpy\")\n",
    "def kuu(x, theta, l):\n",
    "    k = np.zeros((x.size, x.size))\n",
    "    for i in range(x.size):\n",
    "        for j in range(x.size):\n",
    "            k[i,j] = kuu_fn(x[i], x[j], theta, l)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "k_{ff}(x_i,x_j;\\theta,\\phi) &= \\mathcal{L}_{x_i}^\\phi \\mathcal{L}_{x_j}^\\phi k_{uu}(x_i, x_j; \\theta) \\\\\n",
    "&= \\mathcal{L}_{x_i}^\\phi \\left( \\phi k_{uu} + \\frac{\\partial}{\\partial x_j}k_{uu} \\right) \\\\\n",
    "&= \\phi^2 k_{uu} + \\phi \\frac{\\partial}{\\partial x_j}k_{uu} + \\phi \\frac{\\partial}{\\partial x_i}k_{uu} + \\frac{\\partial}{\\partial x_i}\\frac{\\partial}{\\partial x_j}k_{uu} \\\\\n",
    "&= \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2)\\left[ \\phi^2 + 2\\phi |x_i-x_j| + (x_i-x_j)^2 + 1 \\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kff_sym = phi**2*kuu_sym \\\n",
    "            + phi*sp.diff(kuu_sym, x_j) \\\n",
    "            + phi*sp.diff(kuu_sym, x_i) \\\n",
    "            + sp.diff(kuu_sym, x_j, x_i)\n",
    "kff_fn = sp.lambdify((x_i, x_j, theta, l, phi), kff_sym, \"numpy\")\n",
    "def kff(x, theta, l, phi):\n",
    "    k = np.zeros((x.size, x.size))\n",
    "    for i in range(x.size):\n",
    "        for j in range(x.size):\n",
    "            k[i,j] = kff_fn(x[i], x[j], theta, l, phi)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "k_{fu}(x_i,x_j;\\theta,\\phi) &= \\mathcal{L}_{x_i}^\\phi k_{uu}(x_i, x_j; \\theta) \\\\\n",
    "&= \\phi k_{uu} + \\frac{\\partial}{\\partial x_i}k_{uu}  \\\\\n",
    "&= \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2) \\left[ (\\frac{1}{2})2|x_i-x_j| + \\phi \\right] \\\\\n",
    "&= \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2)(\\phi + |x_i-x_j|)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfu_sym = phi*kuu_sym + sp.diff(kuu_sym, x_i)\n",
    "kfu_fn = sp.lambdify((x_i, x_j, theta, l, phi), kfu_sym, \"numpy\")\n",
    "def kfu(x1, x2, theta, l, phi):\n",
    "    k = np.zeros((x2.size, x1.size))\n",
    "    for i in range(x2.size):\n",
    "        for j in range(x1.size):\n",
    "            k[i,j] = kfu_fn(x2[i], x1[j], theta, l, phi)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "k_{uf}(x_i,x_j;\\theta,\\phi) &= \\mathcal{L}_{x_j}^\\phi k_{uu}(x_i, x_j; \\theta) \\\\\n",
    "&= \\phi k_{uu} + \\frac{\\partial}{\\partial x_j}k_{uu}  \\\\\n",
    "&= \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2) \\left[ (\\frac{1}{2})2|x_i-x_j| + \\phi \\right]\\\\\n",
    "&= \\theta exp(-\\frac{1}{2l}(x_i-x_j)^2)(\\phi+|x_i-x_j|)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kuf(x1, x2, theta, l, phi):\n",
    "    return kfu(x1, x2, theta, l, phi).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Compute the negative log marginal likelihood(NLML)\n",
    "\n",
    "The following covariance matrix is the result of our discussion at the end of Chapter 1.3.1, with an added noise parameter:\n",
    "\n",
    "\\begin{align*}\n",
    "K = \\begin{bmatrix}\n",
    "k_{uu}(X_u, X_u; \\theta) + \\sigma_u^2I & k_{uf}(X_u, X_f; \\theta, \\phi) \\\\\n",
    "k_{fu}(X_f, X_u; \\theta, \\phi) & k_{ff}(X_f, X_f; \\theta, \\phi) + \\sigma_f^2I\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "For simplicity, assume $\\sigma_u = \\sigma_f$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{NLML} = \\frac{1}{2} \\left[ log|K| + y^TK^{-1}y + Nlog(2\\pi) \\right]\n",
    "\\end{align*}\n",
    "\n",
    "where $y = \\begin{bmatrix}\n",
    "y_u \\\\\n",
    "y_f\n",
    "\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nlml(params, x1, x2, y1, y2, s):\n",
    "    params = np.exp(params)\n",
    "    K = np.block([\n",
    "        [\n",
    "            kuu(x1, params[0], params[1]) + s*np.identity(x1.size),\n",
    "            kuf(x1, x2, params[0], params[1], params[2])\n",
    "        ],\n",
    "        [\n",
    "            kfu(x1, x2, params[0], params[1], params[2]),\n",
    "            kff(x2, params[0], params[1], params[2]) + s*np.identity(x2.size)\n",
    "        ]\n",
    "    ])\n",
    "    y = np.concatenate((y1, y2))\n",
    "    val = 0.5*(np.log(abs(np.linalg.det(K))) \\\n",
    "               + np.mat(y) * np.linalg.inv(K) * np.mat(y).T)\n",
    "    return val.item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Optimize hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nlml_wp = lambda params: nlml(params, x_u, x_f, y_u, y_f, 1e-6)\n",
    "m = minimize(nlml_wp, np.random.rand(3), method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[ 2.47686625, -0.7450802 ,  0.69374954],\n",
       "       [ 2.47693005, -0.74510427,  0.69374962],\n",
       "       [ 2.47692091, -0.74510869,  0.69374958],\n",
       "       [ 2.47688263, -0.74508511,  0.69374952]]), array([-74.87118536, -74.87118536, -74.87118535, -74.87118535]))\n",
       "           fun: -74.87118535724949\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 321\n",
       "           nit: 174\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([ 2.47686625, -0.7450802 ,  0.69374954])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.90390211,  0.47469623,  2.00120508])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(m.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated value comes very close to the actual value.\n",
    "\n",
    "For the current model, we get the following optimal values of the hyperparameters:\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| $\\theta$  |11.90390211 |\n",
    "| $l$       |0.47469623 |\n",
    "| $\\phi$    |2.00120508 |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
